# import os
# import torch
# import torch.nn as nn
# import torchvision.transforms as transforms
# from torchvision import models
# from flask import Flask, request, jsonify, render_template, url_for, send_from_directory, send_file
# from flask_cors import CORS
# from flask_socketio import SocketIO, emit
# from PIL import Image
# import io
# import json
# import threading
# import cv2
# import numpy as np
# import yfinance as yf
# from werkzeug.utils import secure_filename
# from ultralytics import YOLO
# import urllib.parse
# import re
# import eventlet
# import eventlet.wsgi
#
#
#
#
# # âœ… Flask ì•± ì´ˆê¸°í™”
# app = Flask(__name__)
# CORS(app)  # CORS í—ˆìš©
#
#
# # âœ… ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì • (íŒ€ë³„)
# MODEL_CONFIGS = {
#     "team1": {
#         "model_path": "./resnet50_best_team1_animal.pth",
#         "num_classes": 5,
#         "class_labels": ["ê³ ì–‘ì´", "ê³µë£¡", "ê°•ì•„ì§€", "ê¼¬ë¶ì´", "í‹°ë²³ì—¬ìš°"],
#     },
#     "team2": {
#         "model_path": "./resnet50_best_team2_recycle.pth",
#         "num_classes": 13,
#         "class_labels": [
#             "ì˜ì—…ìš©_ëƒ‰ì¥ê³ ", "ì»´í“¨í„°_cpu", "ë“œëŸ¼_ì„¸íƒê¸°", "ëƒ‰ì¥ê³ ", "ì»´í“¨í„°_ê·¸ë˜í”½ì¹´ë“œ",
#             "ë©”ì¸ë³´ë“œ", "ì „ìë ˆì¸ì§€", "ì»´í“¨í„°_íŒŒì›Œ", "ì»´í“¨í„°_ë¨", "ìŠ¤íƒ ë“œ_ì—ì–´ì»¨",
#             "TV", "ë²½ê±¸ì´_ì—ì–´ì»¨", "í†µëŒì´_ì„¸íƒê¸°"
#         ],
#     },
#     "team3": {
#         "model_path": "./resnet50_best_team3_tools_accuracy_90.pth",
#         "num_classes": 10,
#         "class_labels": [
#             "ê³µêµ¬ í†±", "ê³µì—…ìš©ê°€ìœ„", "ê·¸ë¼ì¸ë”", "ë‹ˆí¼", "ë“œë¼ì´ë²„", "ë§ì¹˜",
#             "ìŠ¤íŒ¨ë„ˆ", "ì „ë™ë“œë¦´", "ì¤„ì", "ìº˜ë¦¬í¼ìŠ¤"
#         ],
#     },
# }
#
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#
#
# # âœ… YOLO ëª¨ë¸ ë¡œë“œ
# yolo_model = YOLO("best.pt")
# # app.config['SERVER_NAME'] = '10.100.201.87:5000'  # Flask ì„œë²„ ì£¼ì†Œì™€ í¬íŠ¸ ì„¤ì •
#
# # âœ… ê²°ê³¼ ì €ì¥ í´ë” ì„¤ì •
# UPLOAD_FOLDER = 'uploads'
# RESULT_FOLDER = 'results'
# os.makedirs(UPLOAD_FOLDER, exist_ok=True)
# os.makedirs(RESULT_FOLDER, exist_ok=True)
#
# processing_status = {}
#
# # ğŸ”¹ 2ï¸âƒ£ YOLO ë¹„ë™ê¸° ì²˜ë¦¬ í•¨ìˆ˜
# def process_yolo(file_path, output_path, file_type):
#     """YOLO ëª¨ë¸ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰"""
#     try:
#         print(f"âœ… [INFO] YOLO ì²˜ë¦¬ ì‹œì‘ - {file_path}")
#
#         if file_type == 'image':
#             results = yolo_model(file_path)
#             result_img = results[0].plot()
#             cv2.imwrite(output_path, result_img)
#
#         elif file_type == 'video':
#             cap = cv2.VideoCapture(file_path)
#             width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#             height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#             fps = int(cap.get(cv2.CAP_PROP_FPS))
#
#             fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#             out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
#
#             while cap.isOpened():
#                 ret, frame = cap.read()
#                 if not ret:
#                     break
#                 results = yolo_model(frame)
#                 result_frame = results[0].plot()
#                 out.write(result_frame)
#
#             cap.release()
#             out.release()
#
#         print(f"âœ… [INFO] YOLO ì²˜ë¦¬ ì™„ë£Œ - {output_path}")
#
#     except Exception as e:
#         print(f"âŒ [ERROR] YOLO ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
#
# @app.route('/download/<filename>')
# def download_file(filename):
#     file_path = os.path.join(RESULT_FOLDER, filename)
#     if not os.path.isfile(file_path):
#         return jsonify({"error": "File not found"}), 404
#     return send_file(file_path, as_attachment=True, download_name=filename)
#
#
#
# # ğŸ”¹ 1ï¸âƒ£ íŒŒì¼ ì—…ë¡œë“œ API (POST ìš”ì²­)
# @app.route('/upload', methods=['POST'])
# def upload_file():
#     if 'file' not in request.files:
#         return jsonify({"error": "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
#
#     file = request.files['file']
#
#     if file.filename == '':
#         return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
#
#     filename = file.filename
#     file_path = os.path.join(UPLOAD_FOLDER, filename)
#     file.save(file_path)
#
#     output_filename = f"result_{filename}"
#     # ê²°ê³¼ íŒŒì¼ì€ RESULT_FOLDERì— ì €ì¥ë©ë‹ˆë‹¤.
#     output_path = os.path.join(RESULT_FOLDER, output_filename)
#
#     print("filename : " + filename)
#     # ì—…ë¡œë“œëœ íŒŒì¼ì˜ í™•ì¥ìë¥¼ í™•ì¸í•˜ì—¬ ì´ë¯¸ì§€(image)ì¸ì§€ ë¹„ë””ì˜¤(video)ì¸ì§€ íŒë³„í•©ë‹ˆë‹¤.
#     if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
#         file_type = 'image'
#     elif filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
#         file_type = 'video'
#     else:
#         # ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì¼ ê²½ìš° 400 ì—ëŸ¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
#         return jsonify({"error": "Unsupported file type"}), 400
#
#     request_id = filename.split(".")[0]  # íŒŒì¼ëª…ì„ ìš”ì²­ IDë¡œ ì‚¬ìš©
#
#     # YOLO ë¹„ë™ê¸° ì²˜ë¦¬
#     thread = threading.Thread(target=process_yolo, args=(file_path, output_path, file_type, request_id))
#     thread.start()
#
#     # âœ… ì—…ë¡œë“œ ì„±ê³µ ì‘ë‹µ
#     return jsonify({
#         "message": "íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ",
#         "filename": filename,
#         "file_url": url_for('uploaded_file', filename=filename, _external=True)
#     }), 200
#
#
# # ğŸ”¹ 2ï¸âƒ£ ì—…ë¡œë“œëœ íŒŒì¼ ì œê³µ API
# @app.route('/uploads/<filename>')
# def uploaded_file(filename):
#     return send_from_directory(UPLOAD_FOLDER, filename)
#
# # âœ… ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# def load_model(model_type):
#     if model_type not in MODEL_CONFIGS:
#         raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ ìœ í˜•: {model_type}")
#
#     config = MODEL_CONFIGS[model_type]
#
#     model = models.resnet50(pretrained=False)
#     num_ftrs = model.fc.in_features
#     model.fc = nn.Linear(num_ftrs, config["num_classes"])
#
#     model.load_state_dict(torch.load(config["model_path"], map_location=device))
#     model.to(device)
#     model.eval()
#
#     return model, config["class_labels"]
#
#
# # âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
# ])
#
#
# # ğŸ”¹ 1ï¸âƒ£ ê¸°ë³¸ Index í™”ë©´ (íŒŒì¼ ì—…ë¡œë“œ UI)
# @app.route("/")
# def index():
#     return render_template('index.html')
#
# # ğŸ”¹ 4ï¸âƒ£ ì´ë¯¸ì§€ ë¶„ë¥˜ API (POST ìš”ì²­)
# @app.route("/predict/<model_type>", methods=["POST"])
# def predict(model_type):
#     if "image" not in request.files:
#         return jsonify({"error": "ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
#
#     file = request.files["image"]
#
#     if file.filename == "":
#         return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
#
#     filename = file.filename
#     sanitized_filename = re.sub(r"[^\w.-]", "_", filename)  # ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ìë¥¼ _ë¡œ ë³€ê²½
#
#     # âœ… YOLOv8 ì²˜ë¦¬ ë¶„ê¸°
#     if model_type == "yolo":
#         file_path = os.path.join(UPLOAD_FOLDER, sanitized_filename)
#         file.save(file_path)
#
#         output_filename = f"result_{sanitized_filename}"
#         output_path = os.path.join(RESULT_FOLDER, output_filename)
#
#         print(f"YOLO ì²˜ë¦¬ ì‹œì‘ predict_yolo , filename : {filename}")
#
#         # íŒŒì¼ ìœ í˜• í™•ì¸
#         if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
#             file_type = 'image'
#         elif filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
#             file_type = 'video'
#         else:
#             return jsonify({"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}), 400
#
#             # âœ… YOLO ë¹„ë™ê¸° ì²˜ë¦¬ (ìŠ¤ë ˆë“œ ì‹¤í–‰ í›„ join)
#         thread = threading.Thread(target=process_yolo, args=(file_path, output_path, file_type))
#         thread.start()
#         thread.join()  # âœ… YOLO ì²˜ë¦¬ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
#
#         # âœ… JSON ì‘ë‹µìœ¼ë¡œ ì´ë¯¸ì§€/ë™ì˜ìƒ ë§í¬ ì „ë‹¬
#         return jsonify({
#             "message": "YOLO ëª¨ë¸ì´ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.",
#             "file_url": url_for('serve_result', filename=os.path.basename(output_path), _external=True),
#             "download_url": url_for('download_file', filename=os.path.basename(output_path), _external=True),
#             "file_type": file_type,
#         })
#
#
#     # âœ… ì¼ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ì²˜ë¦¬
#     else:
#         try:
#             model, class_labels = load_model(model_type)
#
#             image = Image.open(io.BytesIO(file.read())).convert("RGB")
#             image = transform(image).unsqueeze(0).to(device)
#
#             with torch.no_grad():
#                 outputs = model(image)
#                 probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
#                 predicted_class = torch.argmax(probabilities).item()
#                 confidence = probabilities[predicted_class].item() * 100
#
#             result = {
#                 "filename": file.filename,
#                 "predicted_class": class_labels[predicted_class],
#                 "confidence": f"{confidence:.2f}%",
#                 "class_index": predicted_class
#             }
#
#             return jsonify(result)
#
#         except Exception as e:
#             return jsonify({"error": str(e)}), 500
#
#
#
# # ğŸ”¹ 5ï¸âƒ£ ê²°ê³¼ íŒŒì¼ ì œê³µ API
# @app.route('/results/<filename>')
# def serve_result(filename):
#     """ê²°ê³¼ íŒŒì¼ ì œê³µ"""
#     file_path = os.path.join(RESULT_FOLDER, filename)
#
#     # âœ… íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
#     if not os.path.exists(file_path):
#         return jsonify({"error": f"íŒŒì¼ '{filename}' ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 404
#
#     print(f"ğŸ“¢ ê²°ê³¼ íŒŒì¼ ì œê³µ: {file_path}")  # ë¡œê·¸ ì¶œë ¥
#     return send_from_directory(RESULT_FOLDER, filename)
# # ============================================================================================
# # âœ… ì£¼ì‹ ì˜ˆì¸¡ ëª¨ë¸ ì •ì˜ (RNN, LSTM, GRU)
# # ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
# class StockPredictorRNN(nn.Module):  # ê°„ë‹¨í•œ RNN ê¸°ë°˜ ì£¼ì‹ ì˜ˆì¸¡ ëª¨ë¸ ì •ì˜
#     def __init__(self, input_size=4, hidden_size=50, num_layers=2, output_size=1):
#         super(StockPredictorRNN, self).__init__()
#         self.hidden_size = hidden_size
#         self.num_layers = num_layers
#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
#         self.fc = nn.Linear(hidden_size, output_size)
#
#     def forward(self, x):  # ìˆœì „íŒŒ ì •ì˜
#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # ì´ˆê¸° ì€ë‹‰ ìƒíƒœ ì •ì˜
#         out, _ = self.rnn(x, h0)  # RNN ë ˆì´ì–´ë¡œ ë°ì´í„° ì²˜ë¦¬, out ëª¨ì–‘ ì˜ˆì‹œ: [ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì€ë‹‰ í¬ê¸°] (ì˜ˆ: [64, 60, 50])
#         out = self.fc(out[:, -1, :])  # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì€ë‹‰ ìƒíƒœë¡œ ìµœì¢… ì¶œë ¥ê°’ ìƒì„±, out ëª¨ì–‘ ì˜ˆì‹œ: [ë°°ì¹˜ í¬ê¸°, 1] (ì˜ˆ: [64, 1])
#         return out
#
# # ëª¨ë¸ ë¡œë“œ
# model = StockPredictorRNN()  # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# model.load_state_dict(torch.load('./samsungStock.pth', map_location=torch.device('cpu')))  # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
# model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
#
# # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
# scaler = torch.load('./scaler.pth', map_location=torch.device('cpu'))  # ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
#
# #======================================================================================================================
# # ì¶”ê°€1: LSTM ëª¨ë¸ ì •ì˜
# class LSTMModel(nn.Module):  # PyTorchì˜ LSTM ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
#     def __init__(self, input_size=4, hidden_size=128, output_size=1, num_layers=2, dropout=0.3):
#         super(LSTMModel, self).__init__()  # nn.Moduleì˜ ìƒì„±ì í˜¸ì¶œ
#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)  # LSTM ë ˆì´ì–´ ì •ì˜
#         self.fc = nn.Linear(hidden_size, output_size)  # ì™„ì „ ì—°ê²° ë ˆì´ì–´ ì •ì˜
#         self.relu = nn.ReLU()  # í™œì„±í™” í•¨ìˆ˜ ReLU ì •ì˜
#
#     def forward(self, x):  # ìˆœì „íŒŒ í•¨ìˆ˜ ì •ì˜
#         lstm_out, _ = self.lstm(x)  # LSTMì˜ ì¶œë ¥ ê³„ì‚°, lstm_out ëª¨ì–‘ ì˜ˆì‹œ: [ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì€ë‹‰ í¬ê¸°] (ì˜ˆ: [64, 60, 128])
#         last_out = lstm_out[:, -1, :]  # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì¶œë ¥ì„ ì„ íƒ, last_out ëª¨ì–‘ ì˜ˆì‹œ: [ë°°ì¹˜ í¬ê¸°, ì€ë‹‰ í¬ê¸°] (ì˜ˆ: [64, 128])
#         out = self.fc(self.relu(last_out))  # ReLU í™œì„±í™” í›„ ì™„ì „ ì—°ê²° ë ˆì´ì–´ í†µê³¼, out ëª¨ì–‘ ì˜ˆì‹œ: [ë°°ì¹˜ í¬ê¸°, ì¶œë ¥ í¬ê¸°] (ì˜ˆ: [64, 1])
#         return out
#
# # LSTM ëª¨ë¸ ë¡œë“œ
# model2 = LSTMModel()  # LSTM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# model2.load_state_dict(torch.load('./samsungStock_LSTM_60days_basic.pth', map_location=torch.device('cpu')))  # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
# model2.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
# scaler = torch.load('./scaler_LSTM_60days_basic.pth')  # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
#
# #======================================================================================================================
# # ì¶”ê°€2: GRU ëª¨ë¸ ì •ì˜
# class GRUModel(nn.Module):  # PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ GRU(Gated Recurrent Unit) ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤
#     def __init__(self, input_size=4, hidden_size=64, num_layers=1, output_size=1):
#         super(GRUModel, self).__init__()  # nn.Moduleì˜ ìƒì„±ì í˜¸ì¶œ
#         self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)  # GRU ë ˆì´ì–´ ì •ì˜
#         self.fc = nn.Linear(hidden_size, output_size)  # ì™„ì „ ì—°ê²° ë ˆì´ì–´ ì •ì˜
#
#     def forward(self, x):  # ìˆœì „íŒŒ ì •ì˜
#         out, _ = self.gru(x)  # GRU ë ˆì´ì–´ë¥¼ í†µí•´ ì…ë ¥ ì²˜ë¦¬, out ëª¨ì–‘ ì˜ˆì‹œ: [ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì€ë‹‰ í¬ê¸°] (ì˜ˆ: [64, 60, 64])
#         out = self.fc(out[:, -1])  # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ì€ë‹‰ ìƒíƒœë¡œ ì„ í˜• ë ˆì´ì–´ì— ì „ë‹¬, out ëª¨ì–‘ ì˜ˆì‹œ: [ë°°ì¹˜ í¬ê¸°, ì¶œë ¥ í¬ê¸°] (ì˜ˆ: [64, 1])
#         return out
#
# # GRU ëª¨ë¸ ë¡œë“œ
# model3 = GRUModel()  # GRU ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# model3.load_state_dict(torch.load('./samsungStock_GRU.pth', map_location=torch.device('cpu')))  # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
# model3.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
# scaler = torch.load('./scaler_GRU.pth')  # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
#
# @app.route('/predict1', methods=['POST'])
# def predict1():  # RNN ëª¨ë¸ ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸
#     try:
#         data = request.get_json()  # JSON ë°ì´í„°ì—ì„œ ì…ë ¥ ê°’ ì¶”ì¶œ
#         if not data or 'data' not in data or 'period' not in data:  # ë°ì´í„° ê²€ì¦
#             return jsonify({"error": "ìš”ì²­ì— ë°ì´í„° ë˜ëŠ” ê¸°ê°„ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."}), 400
#         input_data = data['data']
#         period = data['period']
#
#         period_days_map = {
#             '1d': 1,
#             '5d': 4,
#             '1mo': 19,
#             '3mo': 58,
#             '6mo': 116,
#             '1y': 239
#         }
#
#         if period not in period_days_map:
#             return jsonify({"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” ê¸°ê°„ì…ë‹ˆë‹¤."}), 400
#
#         expected_length = period_days_map[period]
#
#         if not isinstance(input_data, list) or len(input_data) != expected_length:
#             return jsonify({"error": f"ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. {expected_length}ì¼ì¹˜ Open, High, Low, Close ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”."}), 400
#
#         input_data = np.array(input_data)  # ì…ë ¥ ë°ì´í„° ë°°ì—´ ìƒì„±
#         input_data = scaler.transform(input_data)  # ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ì •ê·œí™”
#         input_data = np.expand_dims(input_data, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
#         input_data = torch.Tensor(input_data)
#
#         with torch.no_grad():
#             prediction = model(input_data).item()  # RNN ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
#
#         prediction = scaler.inverse_transform([[0, 0, 0, prediction]])[0][3]  # ì¢…ê°€ ê¸°ì¤€ìœ¼ë¡œ ì—­ì •ê·œí™”
#
#         return jsonify({"prediction": round(prediction, 2)})
#
#     except Exception as e:
#         return jsonify({"error": "ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500
#
# # LSTM ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸
# @app.route('/predict2', methods=['POST'])
# def predict2():
#     try:
#         data = request.get_json()  # JSON ë°ì´í„°ì—ì„œ ì…ë ¥ ê°’ ì¶”ì¶œ
#         if not data or 'data' not in data or 'period' not in data:
#             return jsonify({"error": "ìš”ì²­ì— ë°ì´í„° ë˜ëŠ” ê¸°ê°„ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."}), 400
#         input_data = data['data']
#         period = data['period']
#
#         period_days_map = {
#             '1d': 1,
#             '5d': 4,
#             '1mo': 19,
#             '3mo': 58,
#             '6mo': 116,
#             '1y': 239
#         }
#
#         if period not in period_days_map:
#             return jsonify({"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” ê¸°ê°„ì…ë‹ˆë‹¤."}), 400
#
#         expected_length = period_days_map[period]
#
#         if not isinstance(input_data, list) or len(input_data) != expected_length:
#             return jsonify({"error": f"ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. {expected_length}ì¼ì¹˜ Open, High, Low, Close ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”."}), 400
#
#         input_data = np.array(input_data)  # ì…ë ¥ ë°ì´í„° ë°°ì—´ ìƒì„±
#         input_data = scaler.transform(input_data)  # ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ì •ê·œí™”
#         input_data = np.expand_dims(input_data, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
#         input_data = torch.Tensor(input_data)
#
#         with torch.no_grad():
#             prediction = model2(input_data).item()  # LSTM ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
#
#         prediction = scaler.inverse_transform([[0, 0, 0, prediction]])[0][3]  # ì¢…ê°€ ê¸°ì¤€ìœ¼ë¡œ ì—­ì •ê·œí™”
#
#         return jsonify({"prediction": round(prediction, 2)})
#
#     except Exception as e:
#         return jsonify({"error": "ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500
#
# # GRU ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸
# @app.route('/predict3', methods=['POST'])
# def predict3():
#     try:
#         data = request.get_json()  # JSON ë°ì´í„°ì—ì„œ ì…ë ¥ ê°’ ì¶”ì¶œ
#         if not data or 'data' not in data or 'period' not in data:
#             return jsonify({"error": "ìš”ì²­ì— ë°ì´í„° ë˜ëŠ” ê¸°ê°„ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."}), 400
#         input_data = data['data']
#         period = data['period']
#
#         period_days_map = {
#             '1d': 1,
#             '5d': 4,
#             '1mo': 19,
#             '3mo': 58,
#             '6mo': 116,
#             '1y': 239
#         }
#
#         if period not in period_days_map:
#             return jsonify({"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” ê¸°ê°„ì…ë‹ˆë‹¤."}), 400
#
#         expected_length = period_days_map[period]
#
#         if not isinstance(input_data, list) or len(input_data) != expected_length:
#             return jsonify({"error": f"ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. {expected_length}ì¼ì¹˜ Open, High, Low, Close ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”."}), 400
#
#         input_data = np.array(input_data)  # ì…ë ¥ ë°ì´í„° ë°°ì—´ ìƒì„±
#         input_data = scaler.transform(input_data)  # ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ì •ê·œí™”
#         input_data = np.expand_dims(input_data, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
#         input_data = torch.Tensor(input_data)
#
#         with torch.no_grad():
#             prediction = model3(input_data).item()  # GRU ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
#
#         prediction = scaler.inverse_transform([[0, 0, 0, prediction]])[0][3]  # ì¢…ê°€ ê¸°ì¤€ìœ¼ë¡œ ì—­ì •ê·œí™”
#
#         return jsonify({"prediction": round(prediction, 2)})
#
#     except Exception as e:
#         return jsonify({"error": "ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500
#
# # ìš”ì²­ ì¼ìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ë°›ê¸°
# @app.route('/get_stock_data', methods=['GET'])
# def get_stock_data():
#     period = request.args.get('period', default='5d')  # ê¸°ë³¸ ìš”ì²­ ê¸°ê°„ ì„¤ì •
#     ticker = '005930.KS'  # ì‚¼ì„±ì „ì ì¢…ëª© ì½”ë“œ
#     data = yf.download(ticker, period=period, interval='1d')  # ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆ ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
#
#     data.columns = data.columns.get_level_values(0)  # MultiIndexê°€ ì„¤ì •ëœ ê²½ìš° ì—´ ì´ë¦„ ë‹¨ìˆœí™”
#
#     if period == '1d':
#         data_subset = data[['Open', 'Low', 'High', 'Close']]  # 1ì¼ì˜ ê²½ìš° ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
#     else:
#         data_subset = data.iloc[:-1][['Open', 'Low', 'High', 'Close']]  # ë‚˜ë¨¸ì§€ ê¸°ê°„ì€ ìµœê·¼ 1ì¼ ì œì™¸í•˜ê³  ë°˜í™˜
#
#     data_subset = data_subset.reset_index()  # Date ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
#     data_subset['Date'] = data_subset['Date'].astype(str)  # Dateë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
#
#     stock_data = data_subset.to_dict(orient='records')  # JSONìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
#
#     return jsonify(stock_data)
#
# # ============================================================================================
#
# # âœ… Flask ì‹¤í–‰
# if __name__ == "__main__":
#     eventlet.wsgi.server(eventlet.listen(("0.0.0.0", 5000)), app)