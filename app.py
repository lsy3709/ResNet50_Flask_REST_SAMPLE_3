# app.py (ë¦¬íŒ©í† ë§ ë°˜ì˜)
import os
import io
import json
import threading
import re
from concurrent.futures import ThreadPoolExecutor

import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
from PIL import Image
from flask import Flask, request, jsonify, send_file, send_from_directory, url_for, render_template
from flask_cors import CORS
from ultralytics import YOLO
import yfinance as yf
from werkzeug.utils import secure_filename
import eventlet
import eventlet.wsgi

import uuid
# ========== Flask ì´ˆê¸°í™” ë° ì„¤ì • ==========
app = Flask(__name__)
CORS(app)
# UPLOAD_FOLDER = 'uploads'
# RESULT_FOLDER = 'results'
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_FOLDER = os.path.join(BASE_DIR, 'uploads')
RESULT_FOLDER = os.path.join(BASE_DIR, 'results')

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)

# ========== ë””ë°”ì´ìŠ¤ ì„¤ì • ==========
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ========== ëª¨ë¸ ì „ì—­ ë³€ìˆ˜ ì„ ì–¸ ==========
rnn_model = None
lstm_model = None
gru_model = None
scalers = {}
yolo_model = YOLO("best.pt")
classification_models = {}
yolo_executor = ThreadPoolExecutor(max_workers=2)  # YOLO ì‘ì—…ìš© ì œí•œ

# ========== ëª¨ë¸ ì •ì˜ ==========
class StockPredictorRNN(nn.Module):
    def __init__(self, input_size=4, hidden_size=50, num_layers=2, output_size=1):
        super().__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(2, x.size(0), 50).to(x.device)
        out, _ = self.rnn(x, h0)
        return self.fc(out[:, -1, :])

class LSTMModel(nn.Module):
    def __init__(self, input_size=4, hidden_size=128, output_size=1, num_layers=2, dropout=0.3):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        last_out = lstm_out[:, -1, :]
        return self.fc(self.relu(last_out))

class GRUModel(nn.Module):
    def __init__(self, input_size=4, hidden_size=64, num_layers=1, output_size=1):
        super().__init__()
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.gru(x)
        return self.fc(out[:, -1])

# ========== ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™” í•¨ìˆ˜ ==========
def initialize_models():
    global rnn_model, lstm_model, gru_model, scalers

    rnn_model = StockPredictorRNN()
    rnn_model.load_state_dict(torch.load('./samsungStock.pth', map_location=device))
    rnn_model.eval()

    lstm_model = LSTMModel()
    lstm_model.load_state_dict(torch.load('./samsungStock_LSTM_60days_basic.pth', map_location=device))
    lstm_model.eval()

    gru_model = GRUModel()
    gru_model.load_state_dict(torch.load('./samsungStock_GRU.pth', map_location=device))
    gru_model.eval()

    scalers['rnn'] = torch.load('./scaler.pth')
    scalers['lstm'] = torch.load('./scaler_LSTM_60days_basic.pth')
    scalers['gru'] = torch.load('./scaler_GRU.pth')

# âœ… ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì • (íŒ€ë³„)
MODEL_CONFIGS = {
    "team1": {
        "model_path": "./resnet50_best_team1_animal.pth",
        "num_classes": 5,
        "class_labels": ["ê³ ì–‘ì´", "ê³µë£¡", "ê°•ì•„ì§€", "ê¼¬ë¶ì´", "í‹°ë²³ì—¬ìš°"],
    },
    "team2": {
        "model_path": "./resnet50_best_team2_recycle.pth",
        "num_classes": 13,
        "class_labels": [
            "ì˜ì—…ìš©_ëƒ‰ì¥ê³ ", "ì»´í“¨í„°_cpu", "ë“œëŸ¼_ì„¸íƒê¸°", "ëƒ‰ì¥ê³ ", "ì»´í“¨í„°_ê·¸ë˜í”½ì¹´ë“œ",
            "ë©”ì¸ë³´ë“œ", "ì „ìë ˆì¸ì§€", "ì»´í“¨í„°_íŒŒì›Œ", "ì»´í“¨í„°_ë¨", "ìŠ¤íƒ ë“œ_ì—ì–´ì»¨",
            "TV", "ë²½ê±¸ì´_ì—ì–´ì»¨", "í†µëŒì´_ì„¸íƒê¸°"
        ],
    },
    "team3": {
        "model_path": "./resnet50_best_team3_tools_accuracy_90.pth",
        "num_classes": 10,
        "class_labels": [
            "ê³µêµ¬ í†±", "ê³µì—…ìš©ê°€ìœ„", "ê·¸ë¼ì¸ë”", "ë‹ˆí¼", "ë“œë¼ì´ë²„", "ë§ì¹˜",
            "ìŠ¤íŒ¨ë„ˆ", "ì „ë™ë“œë¦´", "ì¤„ì", "ìº˜ë¦¬í¼ìŠ¤"
        ],
    },
}

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ğŸ”¹ YOLO ì²˜ë¦¬ í•¨ìˆ˜

def process_yolo(file_path, output_path, file_type):
    try:
        if file_type == 'image':
            results = yolo_model(file_path)
            result_img = results[0].plot()
            cv2.imwrite(output_path, result_img)

        elif file_type == 'video':
            cap = cv2.VideoCapture(file_path)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))

            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                results = yolo_model(frame)
                result_frame = results[0].plot()
                out.write(result_frame)

            cap.release()
            out.release()

    except Exception as e:
        print(f"YOLO ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ğŸ”¹ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜

def load_model(model_type):
    if model_type not in MODEL_CONFIGS:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ ìœ í˜•: {model_type}")

    config = MODEL_CONFIGS[model_type]
    model = models.resnet50(pretrained=False)
    model.fc = nn.Linear(model.fc.in_features, config["num_classes"])
    model.load_state_dict(torch.load(config["model_path"], map_location=device))
    model.to(device)
    model.eval()

    return model, config["class_labels"]

# ğŸ”¹ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ìºì‹± í•¨ìˆ˜

def get_classification_model(model_type):
    if model_type not in classification_models:
        model, class_labels = load_model(model_type)
        classification_models[model_type] = (model, class_labels)
    return classification_models[model_type]

 # ğŸ”¹ 4ï¸âƒ£ ì´ë¯¸ì§€ ë¶„ë¥˜ API (POST ìš”ì²­)
@app.route("/predict/<model_type>", methods=["POST"])
def predict(model_type):
    if "image" not in request.files:
        return jsonify({"error": "ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

    file = request.files["image"]

    if file.filename == "":
        return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

    filename = file.filename
    sanitized_filename = re.sub(r"[^\w.-]", "_", filename)  # ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ìë¥¼ _ë¡œ ë³€ê²½
    unique_id = str(uuid.uuid4())
    sanitized_filename = f"{unique_id}_{sanitized_filename}"

    # âœ… YOLOv8 ì²˜ë¦¬ ë¶„ê¸°
    if model_type == "yolo":
        file_path = os.path.join(UPLOAD_FOLDER, sanitized_filename)
        file.save(file_path)

        output_filename = f"result_{sanitized_filename}"
        output_path = os.path.join(RESULT_FOLDER, output_filename)

        print(f"YOLO ì²˜ë¦¬ ì‹œì‘ predict_yolo , filename : {sanitized_filename}")

        # íŒŒì¼ ìœ í˜• í™•ì¸
        if sanitized_filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
            file_type = 'image'
        elif sanitized_filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
            file_type = 'video'
        else:
            return jsonify({"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}), 400

            # âœ… YOLO ë¹„ë™ê¸° ì²˜ë¦¬ (ìŠ¤ë ˆë“œ ì‹¤í–‰ í›„ join)
        # thread = threading.Thread(target=process_yolo, args=(file_path, output_path, file_type))
        # thread.start()
        # thread.join()  # âœ… YOLO ì²˜ë¦¬ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        yolo_executor.submit(process_yolo, file_path, output_path, file_type)

        # âœ… JSON ì‘ë‹µìœ¼ë¡œ ì´ë¯¸ì§€/ë™ì˜ìƒ ë§í¬ ì „ë‹¬
        return jsonify({
            "message": "YOLO ëª¨ë¸ì´ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.",
            "file_url": url_for('serve_result', filename=os.path.basename(output_path), _external=True),
            "download_url": url_for('download_file', filename=os.path.basename(output_path), _external=True),
            "file_type": file_type,
            "status": "processing"
        })


    # âœ… ì¼ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ì²˜ë¦¬
    else:
        try:
            # model, class_labels = load_model(model_type)
            model, class_labels = get_classification_model(model_type)

            image = Image.open(io.BytesIO(file.read())).convert("RGB")
            image = transform(image).unsqueeze(0).to(device)

            with torch.no_grad():
                outputs = model(image)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                predicted_class = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_class].item() * 100

            result = {
                "filename": file.filename,
                "predicted_class": class_labels[predicted_class],
                "confidence": f"{confidence:.2f}%",
                "class_index": predicted_class
            }

            return jsonify(result)

        except Exception as e:
            return jsonify({"error": str(e)}), 500

# ğŸ”¹ ê²°ê³¼ ì œê³µ API
@app.route('/results/<filename>')
def serve_result(filename):
    file_path = os.path.join(RESULT_FOLDER, filename)
    if not os.path.exists(file_path):
        return jsonify({"error": f"íŒŒì¼ '{filename}' ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 404
    return send_from_directory(RESULT_FOLDER, filename)

@app.route('/uploads/<filename>')
def uploaded_file(filename):
    return send_from_directory(UPLOAD_FOLDER, filename)
@app.route('/download/<filename>')
def download_file(filename):
    file_path = os.path.join(RESULT_FOLDER, filename)
    if not os.path.isfile(file_path):
        return jsonify({"error": "File not found"}), 404
    return send_file(file_path, as_attachment=True, download_name=filename)

# ========== Flask ì‹¤í–‰ ==========
if __name__ == "__main__":
    initialize_models()
    eventlet.wsgi.server(eventlet.listen(("0.0.0.0", 5000)), app)
